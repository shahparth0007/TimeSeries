{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bb0115c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/parthshah/opt/anaconda3/lib/python3.8/site-packages (1.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/parthshah/opt/anaconda3/lib/python3.8/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/parthshah/opt/anaconda3/lib/python3.8/site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /Users/parthshah/opt/anaconda3/lib/python3.8/site-packages (from pandas) (1.20.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/parthshah/opt/anaconda3/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Requirement already satisfied: tslearn in /Users/parthshah/opt/anaconda3/lib/python3.8/site-packages (0.5.2)\n",
      "Requirement already satisfied: numpy in /Users/parthshah/opt/anaconda3/lib/python3.8/site-packages (from tslearn) (1.20.1)\n",
      "Requirement already satisfied: scikit-learn in /Users/parthshah/opt/anaconda3/lib/python3.8/site-packages (from tslearn) (0.24.1)\n",
      "Requirement already satisfied: joblib in /Users/parthshah/opt/anaconda3/lib/python3.8/site-packages (from tslearn) (1.0.1)\n",
      "Requirement already satisfied: Cython in /Users/parthshah/opt/anaconda3/lib/python3.8/site-packages (from tslearn) (0.29.23)\n",
      "Requirement already satisfied: numba in /Users/parthshah/opt/anaconda3/lib/python3.8/site-packages (from tslearn) (0.53.1)\n",
      "Requirement already satisfied: scipy in /Users/parthshah/opt/anaconda3/lib/python3.8/site-packages (from tslearn) (1.6.2)\n",
      "Requirement already satisfied: setuptools in /Users/parthshah/opt/anaconda3/lib/python3.8/site-packages (from numba->tslearn) (52.0.0.post20210125)\n",
      "Requirement already satisfied: llvmlite<0.37,>=0.36.0rc1 in /Users/parthshah/opt/anaconda3/lib/python3.8/site-packages (from numba->tslearn) (0.36.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/parthshah/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->tslearn) (2.1.0)\n",
      "Collecting fbprophet\n",
      "  Using cached fbprophet-0.7.1.tar.gz (64 kB)\n",
      "Requirement already satisfied: Cython>=0.22 in /Users/parthshah/opt/anaconda3/lib/python3.8/site-packages (from fbprophet) (0.29.23)\n",
      "Collecting cmdstanpy==0.9.5\n",
      "  Using cached cmdstanpy-0.9.5-py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: pystan>=2.14 in /Users/parthshah/opt/anaconda3/lib/python3.8/site-packages (from fbprophet) (2.19.1.1)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /Users/parthshah/opt/anaconda3/lib/python3.8/site-packages (from fbprophet) (1.20.1)\n",
      "Requirement already satisfied: pandas>=1.0.4 in /Users/parthshah/opt/anaconda3/lib/python3.8/site-packages (from fbprophet) (1.2.4)\n",
      "Requirement already satisfied: matplotlib>=2.0.0 in /Users/parthshah/opt/anaconda3/lib/python3.8/site-packages (from fbprophet) (3.3.4)\n",
      "Requirement already satisfied: LunarCalendar>=0.0.9 in /Users/parthshah/opt/anaconda3/lib/python3.8/site-packages (from fbprophet) (0.0.9)\n",
      "Requirement already satisfied: convertdate>=2.1.2 in /Users/parthshah/opt/anaconda3/lib/python3.8/site-packages (from fbprophet) (2.3.2)\n",
      "Requirement already satisfied: holidays>=0.10.2 in /Users/parthshah/opt/anaconda3/lib/python3.8/site-packages (from fbprophet) (0.11.3.1)\n",
      "Requirement already satisfied: setuptools-git>=1.2 in /Users/parthshah/opt/anaconda3/lib/python3.8/site-packages (from fbprophet) (1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.0 in /Users/parthshah/opt/anaconda3/lib/python3.8/site-packages (from fbprophet) (2.8.1)\n",
      "Requirement already satisfied: tqdm>=4.36.1 in /Users/parthshah/opt/anaconda3/lib/python3.8/site-packages (from fbprophet) (4.59.0)\n",
      "Requirement already satisfied: pymeeus<=1,>=0.3.13 in /Users/parthshah/opt/anaconda3/lib/python3.8/site-packages (from convertdate>=2.1.2->fbprophet) (0.5.11)\n",
      "Requirement already satisfied: pytz>=2014.10 in /Users/parthshah/opt/anaconda3/lib/python3.8/site-packages (from convertdate>=2.1.2->fbprophet) (2021.1)\n",
      "Requirement already satisfied: hijri-converter in /Users/parthshah/opt/anaconda3/lib/python3.8/site-packages (from holidays>=0.10.2->fbprophet) (2.2.2)\n",
      "Requirement already satisfied: korean-lunar-calendar in /Users/parthshah/opt/anaconda3/lib/python3.8/site-packages (from holidays>=0.10.2->fbprophet) (0.2.1)\n",
      "Requirement already satisfied: ephem>=3.7.5.3 in /Users/parthshah/opt/anaconda3/lib/python3.8/site-packages (from LunarCalendar>=0.0.9->fbprophet) (4.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/parthshah/opt/anaconda3/lib/python3.8/site-packages (from matplotlib>=2.0.0->fbprophet) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/parthshah/opt/anaconda3/lib/python3.8/site-packages (from matplotlib>=2.0.0->fbprophet) (1.3.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /Users/parthshah/opt/anaconda3/lib/python3.8/site-packages (from matplotlib>=2.0.0->fbprophet) (2.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/parthshah/opt/anaconda3/lib/python3.8/site-packages (from matplotlib>=2.0.0->fbprophet) (8.2.0)\n",
      "Requirement already satisfied: six in /Users/parthshah/opt/anaconda3/lib/python3.8/site-packages (from cycler>=0.10->matplotlib>=2.0.0->fbprophet) (1.15.0)\n",
      "Building wheels for collected packages: fbprophet\n",
      "  Building wheel for fbprophet (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fbprophet: filename=fbprophet-0.7.1-py3-none-any.whl size=723195 sha256=0962635af0d1cbd1c85d8711e0b4b1f08247d20ddb2d1a72b90ba2649144a329\n",
      "  Stored in directory: /Users/parthshah/Library/Caches/pip/wheels/d0/d2/ae/c579b7fd160999d35908f3cb8ebcad7ef64ecaca7b78e4c3c8\n",
      "Successfully built fbprophet\n",
      "Installing collected packages: cmdstanpy, fbprophet\n",
      "  Attempting uninstall: cmdstanpy\n",
      "    Found existing installation: cmdstanpy 0.9.68\n",
      "    Uninstalling cmdstanpy-0.9.68:\n",
      "      Successfully uninstalled cmdstanpy-0.9.68\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "prophet 1.0.1 requires cmdstanpy==0.9.68, but you have cmdstanpy 0.9.5 which is incompatible.\u001b[0m\n",
      "Successfully installed cmdstanpy-0.9.5 fbprophet-0.7.1\n",
      "Requirement already satisfied: pmdarima in /Users/parthshah/opt/anaconda3/lib/python3.8/site-packages (1.8.4)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in /Users/parthshah/opt/anaconda3/lib/python3.8/site-packages (from pmdarima) (0.24.1)\n",
      "Requirement already satisfied: statsmodels!=0.12.0,>=0.11 in /Users/parthshah/opt/anaconda3/lib/python3.8/site-packages (from pmdarima) (0.12.2)\n",
      "Requirement already satisfied: setuptools!=50.0.0,>=38.6.0 in /Users/parthshah/opt/anaconda3/lib/python3.8/site-packages (from pmdarima) (52.0.0.post20210125)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /Users/parthshah/opt/anaconda3/lib/python3.8/site-packages (from pmdarima) (1.6.2)\n",
      "Requirement already satisfied: pandas>=0.19 in /Users/parthshah/opt/anaconda3/lib/python3.8/site-packages (from pmdarima) (1.2.4)\n",
      "Requirement already satisfied: numpy>=1.19.3 in /Users/parthshah/opt/anaconda3/lib/python3.8/site-packages (from pmdarima) (1.20.1)\n",
      "Requirement already satisfied: Cython!=0.29.18,>=0.29 in /Users/parthshah/opt/anaconda3/lib/python3.8/site-packages (from pmdarima) (0.29.23)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/parthshah/opt/anaconda3/lib/python3.8/site-packages (from pmdarima) (1.0.1)\n",
      "Requirement already satisfied: urllib3 in /Users/parthshah/opt/anaconda3/lib/python3.8/site-packages (from pmdarima) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/parthshah/opt/anaconda3/lib/python3.8/site-packages (from pandas>=0.19->pmdarima) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/parthshah/opt/anaconda3/lib/python3.8/site-packages (from pandas>=0.19->pmdarima) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/parthshah/opt/anaconda3/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas>=0.19->pmdarima) (1.15.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/parthshah/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn>=0.22->pmdarima) (2.1.0)\n",
      "Requirement already satisfied: patsy>=0.5 in /Users/parthshah/opt/anaconda3/lib/python3.8/site-packages (from statsmodels!=0.12.0,>=0.11->pmdarima) (0.5.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install tslearn\n",
    "!pip install fbprophet\n",
    "!pip install pmdarima\n",
    "import pandas as pd\n",
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "import FORECAST_1001 \n",
    "import FORECAST_1031 \n",
    "import transform\n",
    "# import FORECAST_1036\n",
    "import FORECAST_1034\n",
    "import traintest\n",
    "import FORECAST_1035\n",
    "# import FORECAST_1004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72c02afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_excel(\"Sales_Data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "026e3950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2014-04-01 00:00:00')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['DATE'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52a6251a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>East</th>\n",
       "      <td>2133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>North</th>\n",
       "      <td>2133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>2133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South 1</th>\n",
       "      <td>2133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South 2</th>\n",
       "      <td>2133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>West</th>\n",
       "      <td>2133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         DATE\n",
       "ID           \n",
       "East     2133\n",
       "North    2133\n",
       "Overall  2133\n",
       "South 1  2133\n",
       "South 2  2133\n",
       "West     2133"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[[\"DATE\",\"ID\"]].groupby(\"ID\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "650ee76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import itertools\n",
    "\n",
    "def expandgrid(*itrs):\n",
    "   product = list(itertools.product(*itrs))\n",
    "   return {'Var{}'.format(i+1):[x[i] for x in product] for i in range(len(itrs))}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c07e4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import FORECAST_1001 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b669db53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataExtraction__An error occurred while extracting and merging the 2 dataframes.\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'salesDF' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-53e7f60cbb23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m sales, flags = FORECAST_1001.dataExtraction(category = \"J\", level = \"ID\",salesFromPath = True,\n\u001b[0m\u001b[1;32m      2\u001b[0m                                                 flagsFromPath = False)\n",
      "\u001b[0;32m~/Documents/GitHub/TimeSeries/TimeSeries/FORECAST_1001.py\u001b[0m in \u001b[0;36mdataExtraction\u001b[0;34m(category, level, salesFromPath, flagsFromPath)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0msalesDF\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mflagsDF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextractdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDICT_FLAG_PATH\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcategory\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mdictColNames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0msalesDF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msalesDF\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mflagsDF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dataExtraction__An error occurred while extracting and merging the 2 dataframes.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'salesDF' referenced before assignment"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1fd3441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sales_Data.xlsx'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import config\n",
    "category = \"J\"\n",
    "config.DICT_JEW_PATH[category]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "388c7fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import itertools\n",
    "\n",
    "def expandgrid(*itrs):\n",
    "   product = list(itertools.product(*itrs))\n",
    "   return {'Var{}'.format(i+1):[x[i] for x in product] for i in range(len(itrs))}\n",
    "\n",
    "#level parameter must be case sensitive to the column name in the csv/excel file \n",
    "def extractdata(salesdata_filepath,flags_filepath,level='ID' , salesDF = None,freq=\"D\"):\n",
    "    level=str(level)\n",
    "    #importing flags and sales data \n",
    "    #flags=pd.read_csv(str(flags_filepath))\n",
    "    flags = selectFileFromPath(str(flags_filepath))\n",
    "    \n",
    "    if not salesdata_filepath == \"\":\n",
    "        #salesdata = pd.read_csv(str(salesdata_filepath))\n",
    "        salesdata = selectFileFromPath(str(salesdata_filepath))\n",
    "    else:\n",
    "        salesdata = salesDF\n",
    "    \n",
    "\n",
    "    #Converting DATE in string format to datetime format \n",
    "    flags['DATE'] = pd.to_datetime(flags['DATE'],format='%d-%m-%Y')\n",
    "    salesdata['DATE'] = pd.to_datetime(salesdata['DATE'],format='%d-%m-%Y')\n",
    "\n",
    "    #Extracting min and max DATE from dataset and creating index with all dates in between \n",
    "    mindate=salesdata['DATE'].min()\n",
    "    maxdate=salesdata['DATE'].max()\n",
    "    date_rng = pd.date_range(start=mindate, end=maxdate, freq=freq)\n",
    "\n",
    "    #Extracting all unique regions/stores/cat/PB\n",
    "    unique=set(salesdata.loc[:,level])\n",
    "\n",
    "    #Creating df with all combinations of level and DATE\n",
    "    completedata=expandgrid(unique,date_rng)\n",
    "    completedf=pd.DataFrame(completedata)\n",
    "\n",
    "    #Appropriately renaming columnns of new df\n",
    "    completedf=completedf.rename(columns={'Var1':'ID','Var2':'DATE'})\n",
    "    \n",
    "    #Merging new df with flags and sales dataset \n",
    "    #completedf=pd.merge(flags,completedf,on='DATE')\n",
    "    completedf=pd.merge(completedf,salesdata,how='left',left_on=[\"ID\",'DATE'],right_on=[level,'DATE'])\n",
    "    \n",
    "    #Setting DATE as index of df \n",
    "    completedf = completedf.set_index('DATE')\n",
    "    #completedf=completedf.drop(level,axis=1)\n",
    "    #print(completedf.head())\n",
    "    completedf.columns=['ID',\"SALES\"]\n",
    "    flags = flags.set_index('DATE')\n",
    "    \n",
    "    #Replacing na with 0 \n",
    "    sales=completedf.fillna(0)\n",
    "    flags=flags.fillna(0)\n",
    "    return sales, flags\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "714ae357",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataExtraction(category , level , salesFromPath = True , flagsFromPath = True):\n",
    "    \n",
    "    try:\n",
    "\n",
    "        if salesFromPath == True and flagsFromPath == True:\n",
    "            salesDF , flagsDF = extractdata(config.DICT_JEW_PATH[category] , config.DICT_FLAG_PATH[category] , level)\n",
    "        elif salesFromPath == False:\n",
    "            if category == \"E\":\n",
    "                salesDF = selectData(dictSelectEyewareData[level])\n",
    "            elif category == \"W\":\n",
    "                salesDF = selectData(dictSelectWatchData[level])\n",
    "            elif category == \"J\":\n",
    "                salesDF = selectData(dictSelectJewelData[level])\n",
    "\n",
    "            dictColNames = {\"OVR\" : \"Overall\" , \"REG\" : \"Regional\" , \"STO\" : \"Store\" , \"SKU\" : \"SKU\" , \"CAT\" : \"Category\" , \"CAP\" : \"CAT PB\" }                          \n",
    "\n",
    "            salesDF , flagsDF = extractdata(\"\" , config.DICT_FLAG_PATH[category] , dictColNames[level] , salesDF)\n",
    "        \n",
    "        return salesDF , flagsDF\n",
    "    except:\n",
    "        print(\"dataExtraction__An error occurred while extracting and merging the 2 dataframes.\")\n",
    "        raise\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1cadcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def traintestsplit(data,train=0.7):\n",
    "    try:\n",
    "        train_size=int(len(data)*train)\n",
    "        train, test = data.iloc[:train_size,], data.iloc[train_size:,]\n",
    "        return train,test \n",
    "    \n",
    "    except:\n",
    "        print(\"traintestsplit__An error occured while splitting data into train and test\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae687c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "level=\"ID\",\n",
    "frequency=\"M\",\n",
    "n=1,\n",
    "salesFromPath=True,\n",
    "flagsFromPath=True,\n",
    "transformation=\"\",\n",
    "confidencelevel=0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d513a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selectFileFromPath__An error occurred while fetching file from path.\n",
      "selectFileFromPath__An error occurred while fetching file from path.\n",
      "dataExtraction__An error occurred while extracting and merging the 2 dataframes.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-9282730355eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m sales, flags = FORECAST_1001.dataExtraction(category = \"J\", level = \"ID\",salesFromPath = True,\n\u001b[0m\u001b[1;32m      6\u001b[0m                                                  flagsFromPath = True)\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/TimeSeries/TimeSeries/FORECAST_1001.py\u001b[0m in \u001b[0;36mdataExtraction\u001b[0;34m(category, level, salesFromPath, flagsFromPath)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msalesFromPath\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mflagsFromPath\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0msalesDF\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mflagsDF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextractdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDICT_JEW_PATH\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcategory\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDICT_FLAG_PATH\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcategory\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0msalesFromPath\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcategory\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"E\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/TimeSeries/TimeSeries/FORECAST_1001.py\u001b[0m in \u001b[0;36mextractdata\u001b[0;34m(salesdata_filepath, flags_filepath, level, salesDF, freq)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;31m#Converting DATE in string format to datetime format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m     \u001b[0mflags\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'DATE'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'DATE'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'%d-%m-%Y'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m     \u001b[0msalesdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'DATE'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msalesdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'DATE'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'%d-%m-%Y'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "def MAPE(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true.sum() - y_pred.sum()) / y_true.sum())) * 100\n",
    "\n",
    "sales, flags = FORECAST_1001.dataExtraction(category = \"J\", level = \"ID\",salesFromPath = True,\n",
    "                                                 flagsFromPath = True)\n",
    "\n",
    "unique=set(sales[\"ID\"])\n",
    "algotable = pd.DataFrame()\n",
    "forecast = pd.Series()\n",
    "############################## DATA PRE-PROCESSING ########################\n",
    "#Looping over every individual item in col \"ID\"\n",
    "for unit in unique:\n",
    "    #Subsetting sales and flags data for each unique item in \"ID\" column of\n",
    "    #salesdata df for training and forecasting \n",
    "    print(\"Starting forecast for CATPB: \",unit)\n",
    "    salesdata = pd.Series(sales.loc[sales[\"ID\"]==unit,\"SALES\"])\n",
    "    startdate = salesdata.index[0]\n",
    "    #startdate = salesdata[np.min(salesdata):].index[0]\n",
    "    salesdata = salesdata[startdate:]\n",
    "    flagsdata = flags[startdate:]  \n",
    "\n",
    "    #Grouping data to a weekly level for training/forecasting\n",
    "    if frequency==\"W\":\n",
    "        salesdata = salesdata.resample('W').sum()\n",
    "        flagsdata = flagsdata.drop('WEEKEND_FLAG',axis=1,errors='ignore')\n",
    "        flagsdata = flagsdata.resample('W').mean()\n",
    "\n",
    "    #Grouping data to a monthly level for training/forecasting\n",
    "    if frequency==\"M\":\n",
    "        salesdata = salesdata.resample('M').sum()\n",
    "        flagsdata = flagsdata.drop([\"Start of Month Flag\",\"MONTHEND_FLAG\",\n",
    "                                    \"End of Month Flag\"],axis=1,errors='ignore')\n",
    "        flagsdata = flagsdata.resample('M').mean()   \n",
    "    n = 1    \n",
    "    flagsdf = flagsdata.iloc[len(salesdata):len(salesdata)+n]   \n",
    "    flagsdata = flagsdata.iloc[:len(salesdata)]        \n",
    "\n",
    "    ######### TRAIN-TEST SPLIT #########\n",
    "    trainsales, testsales = traintestsplit(salesdata)\n",
    "    trainflags, testflags = traintestsplit(flagsdata)\n",
    "\n",
    "    ############################# MODEL TRAINING ############################# \n",
    "    #creating dataframe for storing mse for models \n",
    "    errortable = pd.DataFrame()\n",
    "    \n",
    "\n",
    "    ########## ARIMA ##########\n",
    "    #Transforming data to stationarize it \n",
    "    transformeddata = stationarize(trainsales,conflev=0.95)\n",
    "    #Passing scaled data to the arimax model \n",
    "    scaledforecast = FORECAST_1034.arimax(transformeddata[0],len(testsales))\n",
    "    #Inverse scaling the scaled forecasts \n",
    "    arimaforecasts = transform.inverse(scaledforecast,transformeddata)\n",
    "    error = mse(arimaforecasts ,testsales)\n",
    "    error2 = MAPE(testsales,arimaforecasts)\n",
    "    #Appending mse and MAPE to error table \n",
    "    errortable = errortable.append({'Algorithm' : 'ARIMA', 'mse' : error, \n",
    "                                    \"MAPE\":error2},ignore_index=True)            \n",
    "    del scaledforecast, arimaforecasts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fb7570e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ARIMA</td>\n",
       "      <td>3.319490e+01</td>\n",
       "      <td>1.495159e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ARIMAX</td>\n",
       "      <td>2.161639e+14</td>\n",
       "      <td>2.877609e+38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOLT-WINTERS-AANd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e+15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Algorithm          MAPE           mse\n",
       "0              ARIMA  3.319490e+01  1.495159e+12\n",
       "1             ARIMAX  2.161639e+14  2.877609e+38\n",
       "2  HOLT-WINTERS-AANd           NaN  1.000000e+15"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errortable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4d7a5b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transformeddata' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-30425156088e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#Passing scaled data to the arimax model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mscaledforecast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFORECAST_1034\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marimax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformeddata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestsales\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m#Inverse scaling the scaled forecasts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0marimaforecasts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaledforecast\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtransformeddata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'transformeddata' is not defined"
     ]
    }
   ],
   "source": [
    "def MAPE(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true.sum() - y_pred.sum()) / y_true.sum())) * 100\n",
    "\n",
    "\n",
    "#Passing scaled data to the arimax model \n",
    "scaledforecast = FORECAST_1034.arimax(transformeddata[0],len(testsales))\n",
    "#Inverse scaling the scaled forecasts \n",
    "arimaforecasts = transform.inverse(scaledforecast,transformeddata)\n",
    "error = mse(arimaforecasts ,testsales)\n",
    "error2 = MAPE(testsales,arimaforecasts)\n",
    "#Appending mse and MAPE to error table \n",
    "errortable = errortable.append({'Algorithm' : 'ARIMA', 'mse' : error, \n",
    "                                \"MAPE\":error2},ignore_index=True)            \n",
    "del scaledforecast, arimaforecasts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d70cddcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainflags1 = trainflags.iloc[-len(transformeddata[0]):,:]\n",
    "transformeddata[0].index = trainflags1.index\n",
    "scaledforecast = FORECAST_1034.arimax(transformeddata[0],len(testsales),\n",
    "                             trainFlags=trainflags1,forecastFlags=testflags)\n",
    "arimaxforecasts = transform.inverse(scaledforecast,transformeddata)\n",
    "error = mse(arimaxforecasts ,testsales)\n",
    "error2 = MAPE(testsales,arimaxforecasts)\n",
    "errortable = errortable.append({'Algorithm' : 'ARIMAX', 'mse' : error,\n",
    "                                \"MAPE\":error2},ignore_index=True)\n",
    "del transformeddata, scaledforecast, arimaxforecasts, trainflags1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4219e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### HOLT-WINTERS #########\n",
    "category = \"J\"\n",
    "holtMSE,algo = FORECAST_1031.HOLTWINTER(trainsales,testsales,category)\n",
    "if algo == \"AANd\":\n",
    "    #AANd = Additive trend , Additive seasonality , No Damp\n",
    "    errortable = errortable.append({'Algorithm' : 'HOLT-WINTERS-AANd', \n",
    "                                    'mse' : holtMSE},ignore_index=True)                                     \n",
    "\n",
    "elif algo == \"AMNd\":    \n",
    "    #AANd = Additive trend , Multiplicative seasonality , No Damp\n",
    "    errortable = errortable.append({'Algorithm' : 'HOLT-WINTERS-AMNd', \n",
    "                                    'mse' : holtMSE},ignore_index=True)                                 \n",
    "elif algo == \"AAD\":\n",
    "    #AAD = Additive trend , Additive seasonality , With Damp\n",
    "    errortable = errortable.append({'Algorithm' : 'HOLT-WINTERS-AAD', \n",
    "                                    'mse' : holtMSE},ignore_index=True)                                          \n",
    "elif algo == \"AMD\":\n",
    "    #AMD = Additive trend , Multiplicative seasonality , No Damp\n",
    "    errortable = errortable.append({'Algorithm' : 'HOLT-WINTERS-AMD', \n",
    "                                    'mse' : holtMSE},ignore_index=True)                                    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e97be9a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('M',)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a42e32e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Holt winter algo implementation for forecasting\n",
    "def seasonalityPeriod(category, data_freq = \"D\"):\n",
    "    m = config.DICT_SEASONALITY[category][data_freq]\n",
    "    return m\n",
    "\n",
    "\n",
    "def HOLTWINTER(train, test ,category , data_freq = \"D\" , only_error = True, algoIndex = 0):\n",
    "    #Get seasonality period\n",
    "    m = seasonalityPeriod(category,data_freq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ea21aaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "HOLTWINTER(trainsales,testsales,category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cef5c728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ARIMA</td>\n",
       "      <td>3.222314e+00</td>\n",
       "      <td>2.117674e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ARIMAX</td>\n",
       "      <td>6.630659e+14</td>\n",
       "      <td>7.182185e+39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOLT-WINTERS-AANd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e+15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Algorithm          MAPE           mse\n",
       "0              ARIMA  3.222314e+00  2.117674e+12\n",
       "1             ARIMAX  6.630659e+14  7.182185e+39\n",
       "2  HOLT-WINTERS-AANd           NaN  1.000000e+15"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errortable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4dca0f51",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'int' and 'tuple'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-200d25155f8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mflagsdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msalesdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msalesdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'tuple'"
     ]
    }
   ],
   "source": [
    "flagsdata.iloc[len(salesdata):len(salesdata)+n] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "26c382fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2134"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 1\n",
    "len(salesdata)+ n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bbcbc24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying various transformations to data to stationarize it\n",
    "def stationarize(data,conflev=0.95):\n",
    "    #1st order difference\n",
    "    diffdata=transform.difference(data)\n",
    "    output=transform.adfuller(diffdata)\n",
    "    pval = output[1]\n",
    "    if pval>=(1-conflev):\n",
    "        #2nd order difference\n",
    "        diff2data=difference(diffdata)\n",
    "        output=adfuller(diff2data)\n",
    "        pval = output[1]\n",
    "        if pval<(1-conflev):\n",
    "            #print(\"Data transformation: 2nd order differencing\")\n",
    "            transformation = \"dd\"\n",
    "            initial_values= [data.iloc[-1],diffdata.iloc[-1]]\n",
    "            return diff2data,transformation, initial_values\n",
    "    else:\n",
    "        #print(\"Data transformation: 1st order differencing\")\n",
    "        transformation = \"d\"\n",
    "        initial_value= data.iloc[-1]\n",
    "        return diffdata,transformation, initial_value\n",
    "\n",
    "    #Log transformation\n",
    "    if not np.any(data==0):\n",
    "        logdata=np.log(data)\n",
    "        output=adfuller(logdata)\n",
    "        pval = output[1]\n",
    "        #log+differencing\n",
    "        if pval>=(1-conflev):\n",
    "            difflogdata=difference(logdata)\n",
    "            output=adfuller(difflogdata)\n",
    "            pval = output[1]\n",
    "            if pval<(1-conflev):\n",
    "                #print(\"Data transformation: Log + 1st order differencing\")\n",
    "                transformation = \"ld\"\n",
    "                intial_value = logdata.iloc[-1]\n",
    "                return difflogdata, transformation, intial_value\n",
    "        else:\n",
    "            #print(\"Data transformation: Log\")\n",
    "            transformation = \"l\"\n",
    "            return logdata,transformation\n",
    "    else: \n",
    "        data = -data\n",
    "        expdata= np.exp(data)\n",
    "        output=adfuller(expdata)\n",
    "        pval = output[1]\n",
    "        if pval<(1-conflev):\n",
    "            #print(\"Data transformation: Exponential\")\n",
    "            transformation = \"e\"\n",
    "            return expdata, transformation\n",
    "        \n",
    "    boxcoxdata  = stats.boxcox(data)\n",
    "    output=adfuller(boxcoxdata[0])\n",
    "    pval = output[1]\n",
    "    if pval<(1-conflev):\n",
    "        #print(\"Data transformation: Box-Cox\")\n",
    "        transformation = \"bc\"\n",
    "        return boxcoxdata[0], transformation, boxcoxdata[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a607130",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformeddata = stationarize(trainsales,conflev=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35a21130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       -153207.29\n",
       "1        -66406.99\n",
       "2        344137.81\n",
       "3        412407.88\n",
       "4         73347.95\n",
       "           ...    \n",
       "1487     616561.56\n",
       "1488     744913.32\n",
       "1489    -361161.65\n",
       "1490    2292146.36\n",
       "1491   -4405460.21\n",
       "Length: 1492, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformeddata[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "94076cc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1492    1.259057e+06\n",
       "1493    4.910867e+04\n",
       "1494   -1.044443e+05\n",
       "1495    5.842879e+05\n",
       "1496   -5.880066e+05\n",
       "            ...     \n",
       "2127    9.530599e+02\n",
       "2128    9.530599e+02\n",
       "2129    9.530599e+02\n",
       "2130    9.530599e+02\n",
       "2131    9.530599e+02\n",
       "Length: 640, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FORECAST_1034.arimax(transformeddata[0],len(testsales))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4cc0299b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        177067.20\n",
       "1       -151249.70\n",
       "2        451862.95\n",
       "3       1408482.92\n",
       "4      -1211466.87\n",
       "           ...    \n",
       "1487    -361090.50\n",
       "1488    1472891.00\n",
       "1489   -1423051.45\n",
       "1490    2519655.00\n",
       "1491   -3516002.58\n",
       "Length: 1492, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformeddata[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1889a13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformeddata = transform.transform(trainsales,confidencelevel,\n",
    "                                          transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e0c4ab9c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-b83a1915c53e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtransformeddata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "transformeddata[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15b57d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
